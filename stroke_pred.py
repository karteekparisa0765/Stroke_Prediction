# -*- coding: utf-8 -*-
"""stroke_pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/160TYVSwQUlNPku89WX2iy0sYnItJlICJ

# **Libraries**
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder
from sklearn.impute import KNNImputer
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression

"""# **Loading and viewing the dataset**"""

stroke_df = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')
print(stroke_df.head())
print(stroke_df.info())

"""#  Data exploration and summary statistics"""

print(stroke_df.describe())
print(stroke_df.isnull().sum())
print(f"Duplicated entries: {stroke_df.duplicated().sum()}")

# Count plots for categorical variables
fig, axes = plt.subplots(3, 2, figsize=(15, 15))
sns.countplot(x='gender', data=stroke_df, ax=axes[0, 0]).set_title('Gender Distribution')
sns.countplot(x='ever_married', data=stroke_df, ax=axes[0, 1]).set_title('Marriage Status Distribution')
sns.countplot(x='work_type', data=stroke_df, ax=axes[1, 0]).set_title('Work Type Distribution')
sns.countplot(x='Residence_type', data=stroke_df, ax=axes[1, 1]).set_title('Residence Type Distribution')
sns.countplot(x='smoking_status', data=stroke_df, ax=axes[2, 0]).set_title('Smoking Status Distribution')
sns.countplot(x='stroke', data=stroke_df, ax=axes[2, 1]).set_title('Stroke Distribution')
plt.tight_layout()
plt.show()

"""# **Missing data heatmap**"""

sns.heatmap(stroke_df.isnull(), cbar=False, cmap='viridis')
plt.title("Missing Values Heatmap")
plt.show()

"""# **Label encoding for categorical variables**"""

label_encoder = LabelEncoder()
for col in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']:
    stroke_df[col] = label_encoder.fit_transform(stroke_df[col])

"""# **Handling missing values using KNN Imputation**"""

knn_imputer = KNNImputer(n_neighbors=3)
stroke_df['bmi'] = knn_imputer.fit_transform(stroke_df[['bmi']])
print(stroke_df.isnull().sum())

"""# **Pairplot visualization**"""

sns.pairplot(stroke_df, hue='stroke', diag_kind='kde', palette='husl')
plt.suptitle('Pairplot of Features', y=1.02)
plt.show()

"""# **Visualizing outliers using boxplots**"""

plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
sns.boxplot(data=stroke_df['age']).set_title('Age')

plt.subplot(1, 3, 2)
sns.boxplot(data=stroke_df['avg_glucose_level']).set_title('Average Glucose Level')

plt.subplot(1, 3, 3)
sns.boxplot(data=stroke_df['bmi']).set_title('BMI')
plt.tight_layout()
plt.show()

"""#  Distribution plots for continuous variables"""

fig, axes = plt.subplots(1, 3, figsize=(20, 5))
sns.histplot(stroke_df['age'], kde=True, bins=30, ax=axes[0], color='blue').set_title('Age Distribution')
sns.histplot(stroke_df['avg_glucose_level'], kde=True, bins=30, ax=axes[1], color='green').set_title('Glucose Level Distribution')
sns.histplot(stroke_df['bmi'], kde=True, bins=30, ax=axes[2], color='orange').set_title('BMI Distribution')
plt.tight_layout()
plt.show()

"""# **Correlation heatmap**"""

plt.figure(figsize=(12, 8))
correlation_matrix = stroke_df.corr()
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', cbar=True)
plt.title('Correlation Heatmap')
plt.show()

"""# **Handling outliers for 'avg_glucose_level'**"""

Q1 = np.percentile(stroke_df['avg_glucose_level'], 25)
Q3 = np.percentile(stroke_df['avg_glucose_level'], 75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
mean_glucose = stroke_df['avg_glucose_level'].mean()
stroke_df.loc[stroke_df['avg_glucose_level'] > upper_bound, 'avg_glucose_level'] = mean_glucose
stroke_df.loc[stroke_df['avg_glucose_level'] < lower_bound, 'avg_glucose_level'] = mean_glucose

"""# **Class imbalance handling using SMOTE**"""

smote = SMOTE(random_state=42)
X, y = smote.fit_resample(stroke_df.drop(['stroke'], axis=1), stroke_df['stroke'])

sns.countplot(x=y).set_title('Class Distribution After SMOTE')
plt.show()

"""# **Train-test split**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

"""# **Naive Bayes Model**"""

naive_bayes_model = GaussianNB()
naive_bayes_model.fit(X_train, y_train)
nb_pred = naive_bayes_model.predict(X_test)
nb_accuracy = accuracy_score(y_test, nb_pred)
print(f"Naive Bayes Accuracy: {nb_accuracy * 100:.2f}%")

"""# **Decision Tree Model**"""

decision_tree_model = DecisionTreeClassifier(random_state=42)
decision_tree_model.fit(X_train, y_train)
dt_pred = decision_tree_model.predict(X_test)
dt_accuracy = accuracy_score(y_test, dt_pred)
print(f"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%")

"""# **Support Vector Machine (SVM) Model**"""

svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train, y_train)
svm_pred = svm_model.predict(X_test)
svm_accuracy = accuracy_score(y_test, svm_pred)
print(f"SVM Accuracy: {svm_accuracy * 100:.2f}%")

"""# **Logistic Regression Model**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000)
logistic_regression_model.fit(X_train_scaled, y_train)
lr_pred = logistic_regression_model.predict(X_test_scaled)
lr_accuracy = accuracy_score(y_test, lr_pred)
print(f"Logistic Regression Accuracy: {lr_accuracy * 100:.2f}%")

"""# **Comparison of model accuracies**"""

model_accuracies = {
    "Naive Bayes": nb_accuracy * 100,
    "Decision Tree": dt_accuracy * 100,
    "SVM": svm_accuracy * 100,
    "Logistic Regression": lr_accuracy * 100
}

sns.barplot(x=list(model_accuracies.keys()), y=list(model_accuracies.values()))
plt.ylabel('Accuracy (%)')
plt.title('Comparison of Model Accuracies')
plt.show()